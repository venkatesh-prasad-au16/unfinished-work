{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FI_Model Development (Transfer Learning - ResNet50)_v17.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tSNBzg2xzkj"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import random\n",
        "from scipy import ndarray\n",
        "\n",
        "# image processing library\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "from skimage import io\n",
        "from skimage.util import img_as_ubyte, img_as_float\n",
        "from skimage.transform import warp, AffineTransform, ProjectiveTransform\n",
        "from skimage.exposure import equalize_adapthist, equalize_hist, rescale_intensity, adjust_gamma, adjust_log, adjust_sigmoid\n",
        "from skimage.filters import gaussian\n",
        "from skimage.util import random_noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1q6BOQQuHBH"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBahmF2RgXz3"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWFA3t2lECE7",
        "outputId": "6c0911fb-a7c6-41e2-e156-d4727db07cc0"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "drive.mount('/content/drive/', force_remount=True) #DC updated\n",
        "FI_train_dir = \"/content/drive/MyDrive/Foot images4_train\"\n",
        "FI_val_dir = \"/content/drive/MyDrive/Foot images4_val\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkTpxrBpwR1V",
        "outputId": "7994790e-6382-43c8-9c51-20c176a1417f"
      },
      "source": [
        "print(os.listdir(FI_train_dir ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NORMAL ARCH', 'MODERATE', 'MILD', 'HIGH ARCH', 'SEVERE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkG0ZGZbwukI"
      },
      "source": [
        "\"\"\"\r\n",
        "image=[]\r\n",
        "labels=[]\r\n",
        "for f in os.listdir(FI_train_dir):\r\n",
        "  if f=='MILD':\r\n",
        "    for c in os.listdir(os.path.join(FI_train_dir, f)):\r\n",
        "      image.append(os.path.join(FI_train_dir, f,c))\r\n",
        "      labels.append('MILD')\r\n",
        "  if f=='SEVERE':\r\n",
        "    for c in os.listdir(os.path.join(FI_train_dir, f)):\r\n",
        "      image.append(os.path.join(FI_train_dir, f,c))\r\n",
        "      labels.append('SEVERE')\r\n",
        "  if f=='MODERATE':\r\n",
        "    for c in os.listdir(os.path.join(FI_train_dir, f)):\r\n",
        "      image.append(os.path.join(FI_train_dir, f,c))\r\n",
        "      labels.append('MODERATE')\r\n",
        "  if f=='HIGH ARCH':\r\n",
        "      for c in os.listdir(os.path.join(FI_train_dir, f)):\r\n",
        "        image.append(os.path.join(FI_train_dir, f,c))\r\n",
        "        labels.append('HIGH ARCH')\r\n",
        "  if f=='NORMAL ARCH':\r\n",
        "      for c in os.listdir(os.path.join(FI_train_dir, f)):\r\n",
        "        image.append(os.path.join(FI_train_dir, f,c))\r\n",
        "        labels.append('NORMAL ARCH')\r\n",
        "imagedata = {'Images':image, 'labels':labels} \r\n",
        "image_data = pd.DataFrame(imagedata) \r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTjVYqkftR8S",
        "outputId": "52d222ab-cec8-4934-a8af-c33d912aa0ab"
      },
      "source": [
        "batch_size = 32\r\n",
        "image_size = (224, 224)\r\n",
        "\r\n",
        "# this is the augmentation configuration we will use for training\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "        rescale=1./255)\r\n",
        "\r\n",
        "# this is a generator that will read pictures found in\r\n",
        "# subfolers of 'data/train', and indefinitely generate\r\n",
        "# batches of augmented image data\r\n",
        "train_generator = datagen.flow_from_directory(\r\n",
        "        FI_train_dir,  # this is the target directory\r\n",
        "        target_size=image_size, \r\n",
        "        batch_size=batch_size,\r\n",
        "        class_mode='categorical')  \r\n",
        "# this is a similar generator, for validation data\r\n",
        "validation_generator = datagen.flow_from_directory(\r\n",
        "        FI_val_dir,\r\n",
        "        target_size=image_size,\r\n",
        "        batch_size=batch_size,\r\n",
        "        class_mode='categorical')\r\n",
        "classnames = list(train_generator.class_indices.keys())\r\n",
        "print(\"class names: \", classnames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7769 images belonging to 5 classes.\n",
            "Found 2281 images belonging to 5 classes.\n",
            "class names:  ['HIGH ARCH', 'MILD', 'MODERATE', 'NORMAL ARCH', 'SEVERE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1D5zURN1MKW"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout ,GlobalAveragePooling2D\r\n",
        "#from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras import applications\r\n",
        "from tensorflow.keras import Model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3DN7lh95xKL",
        "outputId": "7e010fbe-7fbe-4dd9-ea9e-9477961c0a25"
      },
      "source": [
        "base_model = keras.applications.resnet.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\r\n",
        "print(base_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 4s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua3hRLaUqHa-",
        "outputId": "a2ab825e-a664-48bc-8989-269f7eac0a6a"
      },
      "source": [
        "# Freeze the already-trained layers in the base model\r\n",
        "for layer in base_model.layers:\r\n",
        "  layer.trainable = False\r\n",
        "\r\n",
        "#for layer in base_model.layers[:-5]:\r\n",
        "#  layer.trainable=False\r\n",
        "\r\n",
        "# Create prediction layer for classification of our images\r\n",
        "x = base_model.output\r\n",
        "x = GlobalAveragePooling2D()(x)\r\n",
        "x = Dropout(0.7)(x)\r\n",
        "x = Flatten()(x)\r\n",
        "x = Dense(1024, activation='relu')(x)\r\n",
        "prediction_layer = Dense(5, activation='softmax')(x) \r\n",
        "model = Model(inputs=base_model.input, outputs=prediction_layer)\r\n",
        "\r\n",
        "EPOCHS = 150\r\n",
        "INIT_LR = 1e-4\r\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Now print the full model, which will include the layers of the base model plus the dense layer we added\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5)            5125        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 25,691,013\n",
            "Trainable params: 3,158,021\n",
            "Non-trainable params: 22,532,992\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-bXSBYnX09V"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OesBYOKd6QpK",
        "outputId": "7afe30c2-f14b-4d27-c9ac-b5cf8e1de371"
      },
      "source": [
        "history = model.fit(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\r\n",
        "    validation_data = validation_generator, \r\n",
        "    validation_steps = validation_generator.samples // batch_size,\r\n",
        "    epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "242/242 [==============================] - 4721s 19s/step - loss: 1.7002 - accuracy: 0.2668 - val_loss: 1.5302 - val_accuracy: 0.3371\n",
            "Epoch 2/150\n",
            "242/242 [==============================] - 163s 674ms/step - loss: 1.5014 - accuracy: 0.3342 - val_loss: 1.5157 - val_accuracy: 0.2579\n",
            "Epoch 3/150\n",
            "242/242 [==============================] - 162s 668ms/step - loss: 1.4578 - accuracy: 0.3621 - val_loss: 1.4858 - val_accuracy: 0.3103\n",
            "Epoch 4/150\n",
            "242/242 [==============================] - 163s 676ms/step - loss: 1.4215 - accuracy: 0.3808 - val_loss: 1.5223 - val_accuracy: 0.3310\n",
            "Epoch 5/150\n",
            "242/242 [==============================] - 161s 667ms/step - loss: 1.4058 - accuracy: 0.3974 - val_loss: 1.4897 - val_accuracy: 0.3732\n",
            "Epoch 6/150\n",
            "242/242 [==============================] - 160s 662ms/step - loss: 1.3941 - accuracy: 0.4049 - val_loss: 1.4913 - val_accuracy: 0.3451\n",
            "Epoch 7/150\n",
            "242/242 [==============================] - 161s 667ms/step - loss: 1.3865 - accuracy: 0.4038 - val_loss: 1.4802 - val_accuracy: 0.3763\n",
            "Epoch 8/150\n",
            "242/242 [==============================] - 162s 668ms/step - loss: 1.3589 - accuracy: 0.4234 - val_loss: 1.5264 - val_accuracy: 0.2782\n",
            "Epoch 9/150\n",
            "242/242 [==============================] - 160s 663ms/step - loss: 1.3414 - accuracy: 0.4430 - val_loss: 1.4955 - val_accuracy: 0.3301\n",
            "Epoch 10/150\n",
            "242/242 [==============================] - 164s 678ms/step - loss: 1.3237 - accuracy: 0.4384 - val_loss: 1.5472 - val_accuracy: 0.3319\n",
            "Epoch 11/150\n",
            "242/242 [==============================] - 164s 680ms/step - loss: 1.3204 - accuracy: 0.4322 - val_loss: 1.5266 - val_accuracy: 0.3526\n",
            "Epoch 12/150\n",
            "242/242 [==============================] - 160s 660ms/step - loss: 1.3077 - accuracy: 0.4491 - val_loss: 1.5588 - val_accuracy: 0.3033\n",
            "Epoch 13/150\n",
            "242/242 [==============================] - 161s 668ms/step - loss: 1.3099 - accuracy: 0.4286 - val_loss: 1.5960 - val_accuracy: 0.3301\n",
            "Epoch 14/150\n",
            "242/242 [==============================] - 161s 666ms/step - loss: 1.2837 - accuracy: 0.4537 - val_loss: 1.5987 - val_accuracy: 0.3486\n",
            "Epoch 15/150\n",
            "242/242 [==============================] - 165s 683ms/step - loss: 1.2825 - accuracy: 0.4608 - val_loss: 1.5916 - val_accuracy: 0.3107\n",
            "Epoch 16/150\n",
            "242/242 [==============================] - 161s 668ms/step - loss: 1.2719 - accuracy: 0.4614 - val_loss: 1.6122 - val_accuracy: 0.3081\n",
            "Epoch 17/150\n",
            "242/242 [==============================] - 163s 672ms/step - loss: 1.2383 - accuracy: 0.4931 - val_loss: 1.5251 - val_accuracy: 0.3794\n",
            "Epoch 18/150\n",
            "242/242 [==============================] - 165s 681ms/step - loss: 1.2635 - accuracy: 0.4649 - val_loss: 1.6329 - val_accuracy: 0.3530\n",
            "Epoch 19/150\n",
            "242/242 [==============================] - 163s 674ms/step - loss: 1.2408 - accuracy: 0.4790 - val_loss: 1.7768 - val_accuracy: 0.2790\n",
            "Epoch 20/150\n",
            "242/242 [==============================] - 159s 656ms/step - loss: 1.2423 - accuracy: 0.4882 - val_loss: 1.7675 - val_accuracy: 0.2531\n",
            "Epoch 21/150\n",
            "242/242 [==============================] - 159s 656ms/step - loss: 1.2048 - accuracy: 0.4960 - val_loss: 1.8133 - val_accuracy: 0.3319\n",
            "Epoch 22/150\n",
            "242/242 [==============================] - 164s 677ms/step - loss: 1.2288 - accuracy: 0.4829 - val_loss: 1.6950 - val_accuracy: 0.2962\n",
            "Epoch 23/150\n",
            "242/242 [==============================] - 162s 668ms/step - loss: 1.1945 - accuracy: 0.5006 - val_loss: 1.6937 - val_accuracy: 0.2958\n",
            "Epoch 24/150\n",
            "242/242 [==============================] - 162s 671ms/step - loss: 1.2043 - accuracy: 0.5070 - val_loss: 1.7224 - val_accuracy: 0.3037\n",
            "Epoch 25/150\n",
            "242/242 [==============================] - 163s 674ms/step - loss: 1.1768 - accuracy: 0.5167 - val_loss: 1.9105 - val_accuracy: 0.2566\n",
            "Epoch 26/150\n",
            "242/242 [==============================] - 164s 676ms/step - loss: 1.1432 - accuracy: 0.5232 - val_loss: 1.7017 - val_accuracy: 0.3275\n",
            "Epoch 27/150\n",
            "242/242 [==============================] - 165s 683ms/step - loss: 1.1649 - accuracy: 0.5104 - val_loss: 1.6386 - val_accuracy: 0.3988\n",
            "Epoch 28/150\n",
            "242/242 [==============================] - 165s 683ms/step - loss: 1.1646 - accuracy: 0.5152 - val_loss: 1.7766 - val_accuracy: 0.3270\n",
            "Epoch 29/150\n",
            "242/242 [==============================] - 162s 669ms/step - loss: 1.1370 - accuracy: 0.5421 - val_loss: 1.6898 - val_accuracy: 0.3275\n",
            "Epoch 30/150\n",
            "242/242 [==============================] - 161s 667ms/step - loss: 1.1327 - accuracy: 0.5364 - val_loss: 1.6650 - val_accuracy: 0.3627\n",
            "Epoch 31/150\n",
            "242/242 [==============================] - 164s 677ms/step - loss: 1.1460 - accuracy: 0.5306 - val_loss: 1.9511 - val_accuracy: 0.3261\n",
            "Epoch 32/150\n",
            "242/242 [==============================] - 165s 680ms/step - loss: 1.1186 - accuracy: 0.5356 - val_loss: 1.9647 - val_accuracy: 0.3151\n",
            "Epoch 33/150\n",
            "242/242 [==============================] - 161s 666ms/step - loss: 1.1190 - accuracy: 0.5351 - val_loss: 1.8617 - val_accuracy: 0.3226\n",
            "Epoch 34/150\n",
            "242/242 [==============================] - 163s 673ms/step - loss: 1.0954 - accuracy: 0.5528 - val_loss: 1.6930 - val_accuracy: 0.3649\n",
            "Epoch 35/150\n",
            "242/242 [==============================] - 158s 656ms/step - loss: 1.1042 - accuracy: 0.5548 - val_loss: 1.7789 - val_accuracy: 0.3301\n",
            "Epoch 36/150\n",
            "242/242 [==============================] - 159s 657ms/step - loss: 1.0829 - accuracy: 0.5562 - val_loss: 1.8326 - val_accuracy: 0.3253\n",
            "Epoch 37/150\n",
            "242/242 [==============================] - 162s 671ms/step - loss: 1.0820 - accuracy: 0.5583 - val_loss: 1.8449 - val_accuracy: 0.3631\n",
            "Epoch 38/150\n",
            "242/242 [==============================] - 162s 669ms/step - loss: 1.0779 - accuracy: 0.5684 - val_loss: 1.7997 - val_accuracy: 0.3138\n",
            "Epoch 39/150\n",
            "242/242 [==============================] - 162s 668ms/step - loss: 1.0608 - accuracy: 0.5701 - val_loss: 1.7256 - val_accuracy: 0.3592\n",
            "Epoch 40/150\n",
            "242/242 [==============================] - 162s 669ms/step - loss: 1.0417 - accuracy: 0.5811 - val_loss: 1.8151 - val_accuracy: 0.3385\n",
            "Epoch 41/150\n",
            "242/242 [==============================] - 160s 660ms/step - loss: 1.0523 - accuracy: 0.5788 - val_loss: 1.9935 - val_accuracy: 0.3305\n",
            "Epoch 42/150\n",
            "242/242 [==============================] - 162s 670ms/step - loss: 1.0254 - accuracy: 0.5832 - val_loss: 2.0477 - val_accuracy: 0.3094\n",
            "Epoch 43/150\n",
            "242/242 [==============================] - 160s 663ms/step - loss: 1.0423 - accuracy: 0.5805 - val_loss: 1.9514 - val_accuracy: 0.3605\n",
            "Epoch 44/150\n",
            "242/242 [==============================] - 160s 662ms/step - loss: 1.0400 - accuracy: 0.5805 - val_loss: 2.1413 - val_accuracy: 0.3477\n",
            "Epoch 45/150\n",
            "242/242 [==============================] - 162s 669ms/step - loss: 1.0319 - accuracy: 0.5824 - val_loss: 1.9468 - val_accuracy: 0.3490\n",
            "Epoch 46/150\n",
            "242/242 [==============================] - 158s 652ms/step - loss: 1.0206 - accuracy: 0.5976 - val_loss: 1.8968 - val_accuracy: 0.3442\n",
            "Epoch 47/150\n",
            "242/242 [==============================] - 159s 658ms/step - loss: 1.0343 - accuracy: 0.5761 - val_loss: 2.1544 - val_accuracy: 0.3438\n",
            "Epoch 48/150\n",
            "242/242 [==============================] - 164s 677ms/step - loss: 1.0089 - accuracy: 0.5855 - val_loss: 1.8103 - val_accuracy: 0.3059\n",
            "Epoch 49/150\n",
            "242/242 [==============================] - 164s 676ms/step - loss: 1.0034 - accuracy: 0.5987 - val_loss: 2.0817 - val_accuracy: 0.3319\n",
            "Epoch 50/150\n",
            "242/242 [==============================] - 162s 671ms/step - loss: 1.0093 - accuracy: 0.5969 - val_loss: 2.0568 - val_accuracy: 0.3578\n",
            "Epoch 51/150\n",
            "242/242 [==============================] - 160s 661ms/step - loss: 1.0010 - accuracy: 0.6050 - val_loss: 2.0441 - val_accuracy: 0.3517\n",
            "Epoch 52/150\n",
            "242/242 [==============================] - 164s 678ms/step - loss: 0.9980 - accuracy: 0.5958 - val_loss: 2.0786 - val_accuracy: 0.3380\n",
            "Epoch 53/150\n",
            "242/242 [==============================] - 160s 662ms/step - loss: 1.0043 - accuracy: 0.5947 - val_loss: 2.1440 - val_accuracy: 0.3310\n",
            "Epoch 54/150\n",
            "242/242 [==============================] - 159s 655ms/step - loss: 0.9706 - accuracy: 0.6230 - val_loss: 2.2237 - val_accuracy: 0.3257\n",
            "Epoch 55/150\n",
            "242/242 [==============================] - 161s 666ms/step - loss: 0.9631 - accuracy: 0.6175 - val_loss: 2.0937 - val_accuracy: 0.3468\n",
            "Epoch 56/150\n",
            "242/242 [==============================] - 159s 657ms/step - loss: 0.9638 - accuracy: 0.6121 - val_loss: 2.1288 - val_accuracy: 0.3521\n",
            "Epoch 57/150\n",
            "242/242 [==============================] - 159s 656ms/step - loss: 0.9664 - accuracy: 0.6159 - val_loss: 2.3336 - val_accuracy: 0.3319\n",
            "Epoch 58/150\n",
            "242/242 [==============================] - 162s 669ms/step - loss: 0.9483 - accuracy: 0.6163 - val_loss: 1.9384 - val_accuracy: 0.3327\n",
            "Epoch 59/150\n",
            "242/242 [==============================] - 165s 683ms/step - loss: 0.9749 - accuracy: 0.6089 - val_loss: 2.4027 - val_accuracy: 0.3367\n",
            "Epoch 60/150\n",
            "242/242 [==============================] - 164s 680ms/step - loss: 0.9458 - accuracy: 0.6202 - val_loss: 2.0165 - val_accuracy: 0.3486\n",
            "Epoch 61/150\n",
            "242/242 [==============================] - 162s 668ms/step - loss: 0.9580 - accuracy: 0.6159 - val_loss: 2.2313 - val_accuracy: 0.3270\n",
            "Epoch 62/150\n",
            "242/242 [==============================] - 159s 658ms/step - loss: 0.9388 - accuracy: 0.6218 - val_loss: 2.3493 - val_accuracy: 0.3305\n",
            "Epoch 63/150\n",
            "242/242 [==============================] - 159s 658ms/step - loss: 0.9251 - accuracy: 0.6385 - val_loss: 2.0746 - val_accuracy: 0.2870\n",
            "Epoch 64/150\n",
            "242/242 [==============================] - 160s 661ms/step - loss: 0.9386 - accuracy: 0.6172 - val_loss: 1.9484 - val_accuracy: 0.3631\n",
            "Epoch 65/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.9165 - accuracy: 0.6385 - val_loss: 1.9469 - val_accuracy: 0.3288\n",
            "Epoch 66/150\n",
            "242/242 [==============================] - 160s 662ms/step - loss: 0.9054 - accuracy: 0.6456 - val_loss: 1.9962 - val_accuracy: 0.3099\n",
            "Epoch 67/150\n",
            "242/242 [==============================] - 162s 672ms/step - loss: 0.9254 - accuracy: 0.6301 - val_loss: 2.5825 - val_accuracy: 0.3244\n",
            "Epoch 68/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.9248 - accuracy: 0.6292 - val_loss: 2.4141 - val_accuracy: 0.3041\n",
            "Epoch 69/150\n",
            "242/242 [==============================] - 161s 664ms/step - loss: 0.9122 - accuracy: 0.6432 - val_loss: 2.1945 - val_accuracy: 0.3244\n",
            "Epoch 70/150\n",
            "242/242 [==============================] - 160s 662ms/step - loss: 0.9136 - accuracy: 0.6275 - val_loss: 2.1233 - val_accuracy: 0.3270\n",
            "Epoch 71/150\n",
            "242/242 [==============================] - 161s 664ms/step - loss: 0.9012 - accuracy: 0.6427 - val_loss: 2.4625 - val_accuracy: 0.3319\n",
            "Epoch 72/150\n",
            "242/242 [==============================] - 160s 663ms/step - loss: 0.8913 - accuracy: 0.6436 - val_loss: 2.2779 - val_accuracy: 0.2835\n",
            "Epoch 73/150\n",
            "242/242 [==============================] - 158s 655ms/step - loss: 0.8940 - accuracy: 0.6465 - val_loss: 2.1885 - val_accuracy: 0.3587\n",
            "Epoch 74/150\n",
            "242/242 [==============================] - 160s 663ms/step - loss: 0.8751 - accuracy: 0.6481 - val_loss: 2.1034 - val_accuracy: 0.3530\n",
            "Epoch 75/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.8798 - accuracy: 0.6469 - val_loss: 2.1668 - val_accuracy: 0.3508\n",
            "Epoch 76/150\n",
            "242/242 [==============================] - 157s 650ms/step - loss: 0.8654 - accuracy: 0.6710 - val_loss: 2.2920 - val_accuracy: 0.3512\n",
            "Epoch 77/150\n",
            "242/242 [==============================] - 158s 653ms/step - loss: 0.8612 - accuracy: 0.6659 - val_loss: 2.2714 - val_accuracy: 0.3112\n",
            "Epoch 78/150\n",
            "242/242 [==============================] - 159s 656ms/step - loss: 0.8749 - accuracy: 0.6540 - val_loss: 2.6731 - val_accuracy: 0.3301\n",
            "Epoch 79/150\n",
            "242/242 [==============================] - 158s 652ms/step - loss: 0.8373 - accuracy: 0.6637 - val_loss: 2.3090 - val_accuracy: 0.3314\n",
            "Epoch 80/150\n",
            "242/242 [==============================] - 159s 658ms/step - loss: 0.8468 - accuracy: 0.6716 - val_loss: 2.2352 - val_accuracy: 0.3363\n",
            "Epoch 81/150\n",
            "242/242 [==============================] - 160s 660ms/step - loss: 0.8466 - accuracy: 0.6649 - val_loss: 2.3326 - val_accuracy: 0.3327\n",
            "Epoch 82/150\n",
            "242/242 [==============================] - 160s 661ms/step - loss: 0.8321 - accuracy: 0.6745 - val_loss: 2.4690 - val_accuracy: 0.3499\n",
            "Epoch 83/150\n",
            "242/242 [==============================] - 169s 698ms/step - loss: 0.8533 - accuracy: 0.6707 - val_loss: 2.1631 - val_accuracy: 0.3649\n",
            "Epoch 84/150\n",
            "242/242 [==============================] - 186s 771ms/step - loss: 0.8287 - accuracy: 0.6737 - val_loss: 2.4682 - val_accuracy: 0.3200\n",
            "Epoch 85/150\n",
            "242/242 [==============================] - 196s 810ms/step - loss: 0.8329 - accuracy: 0.6729 - val_loss: 2.2230 - val_accuracy: 0.3261\n",
            "Epoch 86/150\n",
            "242/242 [==============================] - 167s 688ms/step - loss: 0.8129 - accuracy: 0.6901 - val_loss: 2.2166 - val_accuracy: 0.3103\n",
            "Epoch 87/150\n",
            "242/242 [==============================] - 166s 687ms/step - loss: 0.8440 - accuracy: 0.6662 - val_loss: 2.3157 - val_accuracy: 0.3468\n",
            "Epoch 88/150\n",
            "242/242 [==============================] - 164s 676ms/step - loss: 0.8226 - accuracy: 0.6748 - val_loss: 3.0526 - val_accuracy: 0.2927\n",
            "Epoch 89/150\n",
            "242/242 [==============================] - 164s 677ms/step - loss: 0.8228 - accuracy: 0.6908 - val_loss: 2.4415 - val_accuracy: 0.3125\n",
            "Epoch 90/150\n",
            "242/242 [==============================] - 162s 671ms/step - loss: 0.8110 - accuracy: 0.6847 - val_loss: 2.2846 - val_accuracy: 0.3160\n",
            "Epoch 91/150\n",
            "242/242 [==============================] - 161s 667ms/step - loss: 0.8276 - accuracy: 0.6777 - val_loss: 2.5159 - val_accuracy: 0.3482\n",
            "Epoch 92/150\n",
            "242/242 [==============================] - 163s 673ms/step - loss: 0.8198 - accuracy: 0.6815 - val_loss: 2.4250 - val_accuracy: 0.3380\n",
            "Epoch 93/150\n",
            "242/242 [==============================] - 164s 680ms/step - loss: 0.7956 - accuracy: 0.6845 - val_loss: 2.4936 - val_accuracy: 0.3257\n",
            "Epoch 94/150\n",
            "242/242 [==============================] - 163s 675ms/step - loss: 0.7846 - accuracy: 0.6929 - val_loss: 2.6839 - val_accuracy: 0.3512\n",
            "Epoch 95/150\n",
            "242/242 [==============================] - 164s 676ms/step - loss: 0.7991 - accuracy: 0.6924 - val_loss: 2.3655 - val_accuracy: 0.3213\n",
            "Epoch 96/150\n",
            "242/242 [==============================] - 171s 708ms/step - loss: 0.8022 - accuracy: 0.6908 - val_loss: 2.4971 - val_accuracy: 0.3231\n",
            "Epoch 97/150\n",
            "242/242 [==============================] - 163s 673ms/step - loss: 0.7972 - accuracy: 0.6907 - val_loss: 2.2556 - val_accuracy: 0.3332\n",
            "Epoch 98/150\n",
            "242/242 [==============================] - 178s 735ms/step - loss: 0.8019 - accuracy: 0.6802 - val_loss: 2.3553 - val_accuracy: 0.3570\n",
            "Epoch 99/150\n",
            "242/242 [==============================] - 181s 747ms/step - loss: 0.7936 - accuracy: 0.6883 - val_loss: 2.9533 - val_accuracy: 0.3614\n",
            "Epoch 100/150\n",
            "242/242 [==============================] - 176s 725ms/step - loss: 0.7847 - accuracy: 0.6904 - val_loss: 2.3957 - val_accuracy: 0.3614\n",
            "Epoch 101/150\n",
            "242/242 [==============================] - 175s 723ms/step - loss: 0.7738 - accuracy: 0.6998 - val_loss: 2.7138 - val_accuracy: 0.3618\n",
            "Epoch 102/150\n",
            "242/242 [==============================] - 179s 741ms/step - loss: 0.8126 - accuracy: 0.6808 - val_loss: 2.8654 - val_accuracy: 0.3349\n",
            "Epoch 103/150\n",
            "242/242 [==============================] - 179s 739ms/step - loss: 0.7970 - accuracy: 0.6828 - val_loss: 2.5678 - val_accuracy: 0.3354\n",
            "Epoch 104/150\n",
            "242/242 [==============================] - 172s 710ms/step - loss: 0.7659 - accuracy: 0.7037 - val_loss: 2.5127 - val_accuracy: 0.3380\n",
            "Epoch 105/150\n",
            "242/242 [==============================] - 175s 723ms/step - loss: 0.7838 - accuracy: 0.6944 - val_loss: 2.5437 - val_accuracy: 0.3380\n",
            "Epoch 106/150\n",
            "242/242 [==============================] - 179s 739ms/step - loss: 0.7811 - accuracy: 0.6921 - val_loss: 2.8170 - val_accuracy: 0.3508\n",
            "Epoch 107/150\n",
            "242/242 [==============================] - 180s 743ms/step - loss: 0.7668 - accuracy: 0.7065 - val_loss: 2.3439 - val_accuracy: 0.3631\n",
            "Epoch 108/150\n",
            "242/242 [==============================] - 188s 779ms/step - loss: 0.7338 - accuracy: 0.7121 - val_loss: 2.3280 - val_accuracy: 0.3305\n",
            "Epoch 109/150\n",
            "242/242 [==============================] - 171s 706ms/step - loss: 0.7494 - accuracy: 0.7034 - val_loss: 2.5160 - val_accuracy: 0.2623\n",
            "Epoch 110/150\n",
            "242/242 [==============================] - 156s 643ms/step - loss: 0.7439 - accuracy: 0.7156 - val_loss: 2.9875 - val_accuracy: 0.3327\n",
            "Epoch 111/150\n",
            "242/242 [==============================] - 156s 646ms/step - loss: 0.7422 - accuracy: 0.7136 - val_loss: 2.6466 - val_accuracy: 0.3363\n",
            "Epoch 112/150\n",
            "242/242 [==============================] - 156s 645ms/step - loss: 0.7600 - accuracy: 0.7010 - val_loss: 2.7385 - val_accuracy: 0.3415\n",
            "Epoch 113/150\n",
            "242/242 [==============================] - 157s 648ms/step - loss: 0.7472 - accuracy: 0.7112 - val_loss: 2.5365 - val_accuracy: 0.3402\n",
            "Epoch 114/150\n",
            "242/242 [==============================] - 158s 651ms/step - loss: 0.7616 - accuracy: 0.7096 - val_loss: 3.1866 - val_accuracy: 0.3385\n",
            "Epoch 115/150\n",
            "242/242 [==============================] - 158s 653ms/step - loss: 0.7279 - accuracy: 0.7177 - val_loss: 2.7050 - val_accuracy: 0.3389\n",
            "Epoch 116/150\n",
            "242/242 [==============================] - 158s 652ms/step - loss: 0.7449 - accuracy: 0.7060 - val_loss: 2.5881 - val_accuracy: 0.3213\n",
            "Epoch 117/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.7397 - accuracy: 0.7133 - val_loss: 2.6136 - val_accuracy: 0.3187\n",
            "Epoch 118/150\n",
            "242/242 [==============================] - 158s 655ms/step - loss: 0.7388 - accuracy: 0.7117 - val_loss: 2.3960 - val_accuracy: 0.3314\n",
            "Epoch 119/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.7316 - accuracy: 0.7209 - val_loss: 2.7953 - val_accuracy: 0.3301\n",
            "Epoch 120/150\n",
            "242/242 [==============================] - 158s 653ms/step - loss: 0.7218 - accuracy: 0.7154 - val_loss: 2.6769 - val_accuracy: 0.3129\n",
            "Epoch 121/150\n",
            "242/242 [==============================] - 159s 657ms/step - loss: 0.7188 - accuracy: 0.7231 - val_loss: 2.3730 - val_accuracy: 0.3367\n",
            "Epoch 122/150\n",
            "242/242 [==============================] - 157s 650ms/step - loss: 0.7325 - accuracy: 0.7145 - val_loss: 2.5465 - val_accuracy: 0.3495\n",
            "Epoch 123/150\n",
            "242/242 [==============================] - 158s 655ms/step - loss: 0.7374 - accuracy: 0.7135 - val_loss: 2.6002 - val_accuracy: 0.3173\n",
            "Epoch 124/150\n",
            "242/242 [==============================] - 158s 653ms/step - loss: 0.7065 - accuracy: 0.7297 - val_loss: 2.9023 - val_accuracy: 0.3169\n",
            "Epoch 125/150\n",
            "242/242 [==============================] - 159s 659ms/step - loss: 0.7112 - accuracy: 0.7222 - val_loss: 2.7250 - val_accuracy: 0.2949\n",
            "Epoch 126/150\n",
            "242/242 [==============================] - 158s 654ms/step - loss: 0.7192 - accuracy: 0.7224 - val_loss: 2.6001 - val_accuracy: 0.2984\n",
            "Epoch 127/150\n",
            "242/242 [==============================] - 160s 660ms/step - loss: 0.7199 - accuracy: 0.7189 - val_loss: 2.7748 - val_accuracy: 0.3310\n",
            "Epoch 128/150\n",
            " 70/242 [=======>......................] - ETA: 1:28 - loss: 0.7341 - accuracy: 0.7254"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U45xw5gW6UZZ"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs_range = range(len(history.history['val_loss']))\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 15))\r\n",
        "plt.subplot(2, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(2, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPw9WdXQeeMD"
      },
      "source": [
        "#from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOCKGEyLejqi"
      },
      "source": [
        "# serialize model to JSON\r\n",
        "#model_json = model.to_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLVZhYC3epzD"
      },
      "source": [
        "#with open(\"/content/drive/MyDrive/Foot Models/model_v4.json\", \"w\") as json_file:\r\n",
        "#  json_file.write(model_json)\r\n",
        "#model.save_weights(\"model_v4.h5\")\r\n",
        "#print(\"Saved model to disk\")\r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlHwCUW0lZhA"
      },
      "source": [
        "#saved_model=FI_train_dir + '/saved_model2'\r\n",
        "#model.save(saved_model,save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdgcjHek8ggS"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_enpNyoL9Vge"
      },
      "source": [
        "\r\n",
        "#from google.colab import files\r\n",
        "#files.download(\"saved_model4.zip\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpH7j7xm-MyG"
      },
      "source": [
        "#zip -r /content/saved_model4.zip /content/saved_model4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}